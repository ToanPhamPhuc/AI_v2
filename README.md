# Flappy Bird AI - Multiple Approaches

This project implements different AI approaches to play Flappy Bird, from traditional Q-Learning to modern Deep Q-Learning (DQN).

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install -r requirements.txt
```

### Training Options

#### 1. Q-Table AI (Traditional)
```bash
python trains/qLearning/continuous_train.py
```

#### 2. Deep Q-Learning (DQN)
```bash
python trains/dQLearning/dqn_train.py
```

#### 3. Multi-AI Training
```bash
python trains/qLearning/multi_ai_train.py
```

### Testing Trained AIs

#### Test Q-Table AI
```bash
python tests/test_ai.py
```

#### Test DQN AI
```bash
python tests/test_dqn.py
```

## ğŸ“ Project Structure

```
AI_v2/
â”œâ”€â”€ ai/                    # AI implementations
â”‚   â”œâ”€â”€ ai_agent.py       # Q-Table based AI
â”‚   â”œâ”€â”€ dqn_agent.py      # Deep Q-Learning AI
â”‚   â””â”€â”€ training_loop.py  # Training utilities
â”œâ”€â”€ config/               # Configuration files
â”‚   â””â”€â”€ config.py         # Game and AI parameters
â”œâ”€â”€ data/                 # Data storage (organized)
â”‚   â”œâ”€â”€ scores/           # High score files
â”‚   â”œâ”€â”€ jsons/            # Q-tables and JSON data
â”‚   â””â”€â”€ pth/              # PyTorch model files
â”œâ”€â”€ game/                 # Game engine
â”‚   â”œâ”€â”€ main.py           # Main game logic
â”‚   â””â”€â”€ reward_system.py  # Reward calculation
â”œâ”€â”€ readme/               # Documentation
â”‚   â”œâ”€â”€ README.md         # Main documentation
â”‚   â””â”€â”€ README_DQN.md     # DQN-specific documentation
â”œâ”€â”€ tests/                # Test scripts
â”‚   â”œâ”€â”€ test_ai.py        # Test Q-table AI
â”‚   â””â”€â”€ test_dqn.py       # Test DQN AI
â”œâ”€â”€ trains/               # Training scripts (organized)
â”‚   â”œâ”€â”€ qLearning/        # Q-Table training scripts
â”‚   â”‚   â”œâ”€â”€ continuous_train.py
â”‚   â”‚   â”œâ”€â”€ multi_ai_train.py
â”‚   â”‚   â””â”€â”€ train_ai.py
â”‚   â””â”€â”€ dQLearning/       # DQN training scripts
â”‚       â””â”€â”€ dqn_train.py
â”œâ”€â”€ flappy-bird/          # Original game assets
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
```

## ğŸ“š Documentation

- **[Main Documentation](readme/README.md)** - Complete project overview and usage guide
- **[DQN Implementation Details](readme/README_DQN.md)** - Deep Q-Learning specific documentation

## ğŸ® Controls

During training:
- **Q**: Quit training
- **A**: Toggle coordinate axes
- **H**: Toggle hitboxes
- **C**: Toggle collision zones
- **B**: Clear pipe heatmap
- **G**: Toggle gap distance display

## ğŸ“Š Performance Comparison

| Approach | State Space | Memory Usage | Learning Speed | Generalization |
|----------|-------------|--------------|----------------|----------------|
| Q-Table | Discrete | High | Fast initial | Poor |
| DQN | Continuous | Low | Consistent | Excellent |
| Multi-AI | Discrete | High | Very fast | Good |

## ğŸ”§ Configuration

All parameters are configurable in `config/config.py`:

- **Game settings**: Screen size, physics, pipe gap
- **AI parameters**: Learning rates, exploration, rewards
- **DQN settings**: Network architecture, batch size, memory
- **File paths**: Organized data storage locations

## ğŸ¯ Next Steps

1. **Start with Q-Table**: Understand basic RL concepts
2. **Try DQN**: Experience modern deep RL
3. **Experiment**: Tune parameters and try new approaches
4. **Extend**: Add new features or algorithms

Happy training! ğŸ¦ğŸš€ 